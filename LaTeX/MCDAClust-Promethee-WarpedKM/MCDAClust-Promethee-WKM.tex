%\documentclass{iosart2c}
\documentclass[]{elsarticle}

\usepackage{natbib}
\usepackage{amsmath,amsthm,mathtools}
\usepackage{amssymb}
\usepackage{mathtools, cuted}

\usepackage[table, dvipsnames]{xcolor}
\usepackage{verbatim}

\usepackage{mathrsfs}
\usepackage{stfloats}
\usepackage{tabularx}
\usepackage{subfigure}

\usepackage{xtab,booktabs}
\usepackage{arydshln}
\usepackage{multirow}
\usepackage{tikz,ifthen,calc}
\usepackage{pgfplots}
\pgfplotsset{compat=1.11}
\usepackage{tkz-fct}
\usepackage{color,colortbl}
\usepackage[labelfont=bf]{caption}

\usepackage{collcell}
\usepackage{hhline}
\usepackage{pgf}

\def\colorModel{hsb} %You can use rgb or hsb

\newcommand\ColCell[1]{
  \pgfmathparse{#1<1?1:0}  %Threshold for changing the font color into the cells
    \ifnum\pgfmathresult=0\relax\color{white}\fi
  \pgfmathsetmacro\compA{0}      %Component R or H
  \pgfmathsetmacro\compB{#1} %Component G or S
  \pgfmathsetmacro\compC{1}      %Component B or B
  \edef\x{\noexpand\centering\noexpand\cellcolor[\colorModel]{\compA,\compB,\compC}}\x #1
  } 
\newcolumntype{E}{>{\collectcell\ColCell}m{0.4cm}<{\endcollectcell}}  %Cell width


\usetikzlibrary{graphdrawing}
%\usetikzlibrary{graphicx}
%\usegdlibrary{trees}
\usetikzlibrary{shapes,decorations,arrows}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows.meta}


\usepackage{enumitem}
\usepackage{algorithmic}
\usepackage{graphicx}
%\usepackage{subfig,graphicx}
\usepackage[titletoc,title]{appendix}

%\usepackage[blocks]{authblk}
%\newenvironment{keywords}{\noindent\textbf{Keywords:}}{}

\theoremstyle{definition}
\newtheorem*{inner}{\innerheader}
\newcommand{\innerheader}{}
\newenvironment{defi}[1]
 {\renewcommand\innerheader{#1}\begin{inner}}
 {\end{inner}}

\tolerance=1
\emergencystretch=\maxdimen
\hyphenpenalty=10000
\hbadness=10000

\newtheorem{prop}{Theorem}

\newtheorem{cond}{Condition}

\newcolumntype{d}[1]{D{.}{.}{#1}}



\journal{}
\bibliographystyle{model2-names}\biboptions{authoryear}

\begin{document}
\begin{frontmatter}                           % The preamble begins here.


\title{Multi-criteria ordered clustering with stochastic parameters: Application to the Human Development Index}


\author[utc]{Javier Pereira$^{*,}$\cortext[cor1]}
\author[ap]{Pedro Contreras}
\author[ufpe]{Danielle C. Morais}
\author[itesm]{Pilar Arroyo-L\'opez}



\cortext[cor1]{Corresponding author at: xjavierpereira7@gmail.com (J.Pereira)}

\address[utc]{Universidad Tecnol\'ogica de Chile Inacap, Santiago, Chile (xjavierpereira7@gmail.com); \\}
\address[ap]{WMG, The University of Warwick, UK (pedro.contreras@gmail.com);}
\address[ufpe]{Universidade Federal de Pernambuco, CDSID (dcmorais@cdsid.org.br);}
\address[itesm]{Tecnologico de Monterrey, Campus Toluca, M\'exico (pilar.arroyo@itesm.mx);}



\begin{abstract}
Development indices have been proposed as a mean to encourage nations to focus on people, economic and sustainability  capabilities to develop a country.  Usually, an index computation allows to build a ranking which in turns is used to segment the set of  elements into homogeneous groups.   Several studies have proposed non-compensatory multi-criteria approaches to compute these indices, mainly because it could lead to a better ranking and segmentation. Approaches are based on clustering techniques which intend to deal with a main difficulty: how to build a completely ordered partitioning of countries being ranked.  However, there is not approaches dealing with uncertain parameters and imprecise data, a main issue in development indices analysis.  In this paper, a non-compensatory ordered clustering approach is proposed which uses the rationale of PROMETHEE II multi-criteria method for ranking countries and a $K$-means-based algorithm to find clusters, which integrates robustness analysis by considering uncertain parameters.  An application to the Human Development Index is performed. We show that this is a promising approach in contexts of stochastic information. Limitations are discussed and future research is proposed.
\end{abstract}

\begin{keyword}
HDI \sep clustering \sep $K$-means \ \sep outranking relation 
\end{keyword}

\end{frontmatter}


\section{Introduction}

%Since 1990, the United Nations Development Programme (UNDP) releases the Human Development Index (HDI) to emphasize that people and their capabilities should be the ultimate criteria for assessing the development of a country, not only economic growth. The 2018 HDI ranking process evaluates  189 United Nations countries on the basis of three criteria: the life expectancy, the years of education and the Gross National Income (GNI). In addition, based on the HDI quartiles, four ordered groups of countries can be identified: very high human development, high human development, medium human development, and low human development.  

Development indices  are broadly used in business, policy-making, research, development-political debates, allocation of development aid, international climate accord designs, and economics \citep{Wolff2011}. However, these have been object of  main criticisms \citep{Noorbakhsh1998, Berenger2007, Klugman2011, Martinez2013}: (1) the compensatory effect; (2) the underlying concepts and available information to define and compute the dimensions used to build an index; (3) the categorization process used to segment objects of analysis.  For instance, the Human Development Index, released by United Nations Development Programme (UNDP),   evaluates  189 United Nations countries on the basis of three criteria: the life expectancy, the years of education and the Gross National Income (GNI).  Its computation considers that a country exhibiting a bad performance in one criteria, can be compensated with a good performance in another. However, this is not desirable since, for instance, bad health indices can be hidden by good GNI, which can exacerbe inequality in access to health systems.   

Non-compensatory  methods have been proposed as an alternative to the development indices calculation methods. For instance, in the case of HDI, \cite{Natoli2011} analyze three aggregation techniques designed for benchmarking and ranking of countries according to aggregated dimensions: additive methods, geometric aggregations, and non-compensatory methods.  They focus on the Condorcet approach as a non-compensatory aggregation technique for progress measures.  \cite{Lozano2009} propose to use the minimum of the component indexes in HDI instead of the arithmetic average. \cite{Mazziotta2015} compare two non-compensatory composite indices for measuring multidimensional phenomena and monitoring their changes over time: a non-linear composite index and a two-parameter function, which is an intermediate case between a compensatory and a full non-compensatory index. The authors found that the non-linear composite seems to be less compensatory that the second one. 

Usually, afterwards the computation of development indices, a ranking process is performed, followed by a segmentation step which is used to identify groups of interests.  However, several scholars have proposed that ordered clustering strategies could be better adapted to that purpose. These are based on non-compensatory multi-criteria decision analysis (MCDA) approaches  \citep{DeSmet2014}.    \cite{Chen2018} propose a PROMETHEE-based algorithm, which  integrates the $K$-means rationale, to cluster countries in the HDI Report. They found that the ordered clustering is highly consistent with the HDI ranks. \cite{DeSmet2012} propose an exact multi-criteria algorithm to find ordered categories, based on valued preference degrees.   \cite{Boujelben2016} propose an approach that integrates PROMETHEE and $K$-means, a popular greedy algorithm for partitioning a set of elements into a pre-defined number of clusters so as to minimize the distances to the cluster centroids (the cluster centers). The underlying idea of their approach is based on the notion of belief distance between the alternatives and the centroids. \cite{Monteiro2018} propose a supervised classification approach based on the ELECTRE TRI method in which categories are defined \emph{a priori} by using fixed category boundaries. Different from other proposals using the outranking-based models, these authors consider that there is no imprecise data in the information sources. Usually, these methods proceed in three step:  1) each pair of candidates is compared in terms of preferences; 2) clusters are built, partially based on the preferences information; 3) clusters are ordered by eliminating inconsistencies \citep{Fernandez2010}. The last step could be time consuming if the whole space of possibilities should  be explored to detect inconsistencies.  \cite{Leiva2013} proposed an interesting algorithm called Warped-$K$-means that could be used to solve this problem by first ranking the set of candidates and then applying an $O(n)$ process to find clusters. Although this method is not specific for multi-criteria problems, we propose an adaptation to be used in our approach.

Computation of development indices also  reveals an issue related to the information available for evaluating some of the relevant dimensions.  Several types of imperfect information have been highlighted by authors analyzing the quality of information used in the development indices calculation. Thus, the weighting process assigning equal importance levels to dimensions in HDI has been criticized and methods to deal with have been proposed \citep{Zheng2015}. In addition, the importance of considering imprecise data in constructing composite indicators has been remarked \citep{Cherchye2011}.  There are multiple indicators used for different kind of indexes, for instance, the Environmental Performance Index, the Internal Market Index, the Human Development Index, or the Technology Achievement Index. However, for some indicators only interval information is available, within what a true value is believed to lie.   \cite{Wolff2011} analyzed three sources of data error in HDI calculation and classification: measurement error due to data revisions, data error due to formula updating and misclassification due to inconsistent categories cut-off values. Actually,  measurement error from data updating impacts the rough data, the indices normalization and the HDI calculation. They found that from 11\% up to 34\% of all countries could be interpreted as misclassified in the development categories. These authors also found that on average the expected absolute deviation is nine rank positions. These results mean that interpretation of HDI ranks must be very careful.  Moreover, methods applied to HDI, which are based on the outranking relation, as for instance those using the PROMETHEE or the ELECTRE TRI methods, consider stable parameters.  However, this choice seems to be inadequate because of imprecision introduced by data updating and inconsistent categories cut-off values.  Thus, parameter values could be supposed to be uncertain, something that has not been yet considered in the ordered clustering literature, as applied to development indices.

In this article, a stochastic approach for ordered clustering is proposed, such that:  (1) actions (e.g., countries) are first ranked by using the PROMETHEE II method rationale; (2)  ordered clusters are built by using the Warped-$K$-means approach; (3) uncertain thresholds and criteria weights are considered such that the approach integrates  Monte Carlo Simulation and robustness analysis is performed. An application to the HDI problem is performed.

The article is organized as follows. In Section \ref{notation} basics of the clustering approach are presented. Section \ref{rule} presents the clustering approach. In Section \ref{application},  countries included in the HDI 2018 report are clustered by following the proposed approach.  Results are presented and discussed.  Limitations of this approach and final conclusions are described in Section \ref{conclusions}.

%\section{Human Development Index}
%
%Since the first publication in 1990, the Human Development Index has been used as a benchmark to encourage development of nations and to foster policy makers to focus on three dimensions:  long and healthy life, access to knowledge and a decent standard of living.  The HDI is the geometric mean of normalized indices for each of the three dimensions, constructed from four indicators \citep{UNDP2019}: Life expectancy at birth (LE); Expected years of schooling (EYS); Mean years of schooling (MYS); and Gross National Income per capita (GNIpc) .  
%
%In order to calculate the HDI, two steps are applied: (1) Creating the dimension indices; (2) Aggregating the dimension indices into the HDI.  Step (1) consists of normalizing the four mentioned indicators according to the following formula:
%
%\begin{equation}
%\mbox{Dimension index}=\frac{\mbox{indicator value - minimum value}}{\mbox{maximum value - minimum value}}. \label{index}
%\end{equation}
%
%\noindent
%In the case of the two normalized education indices, the arithmetic mean is taken.  For the GNI, the natural logarithm of the indicator, the minimum and the maximum values is taken. Next, in Step (2), the geometric mean of indices is taken, as follows:
%
%\begin{equation}
%HDI= (I_{Health} \cdot I_{Education} \cdot I_{Income})^{1/3}. \label{HDI}
%\end{equation}
%
%\noindent
%It is worth to note that in this formula the same weights for all dimensions are given.   Based on the 2014 HDI, four categories of human development achievements are defined, using fixed cutoff points (COP) calculated using the quartiles ($q$) from the distributions of the component indicators averaged over 2004–2013:
%
%\begin{equation}
%COP_q= HDI(LE_q,EYS_q,MYS_q,GNIpc_q), \, q=1,2,3. \label{COP}
%\end{equation}
%
%\noindent
%These quartiles are used in the 2019's Report, as follows:
%
%
%\begin{table}[hbtp]
%\centering
%\begin{tabular}{ll}
%Category						&Limits \\
%\hline
%Very high human development 		& 0.800 and above \\
%\hline
%High human development			& 0.700-0.799		\\
%\hline
%Medium human development		& 0.550-0.699		\\
%\hline
%Low human development			& Below 0.550\\
%\hline
%\end{tabular}
%\end{table}
%
%
%%\subsection{HDI clustering problem}
%
%Three main criticisms to HDI have been reported by different authors \citep{Noorbakhsh1998, Berenger2007, Klugman2011, Martinez2013}: (1) the compensatory effect; (2) the underlying concepts to define the dimensions; (3) the categorization process that uses the COP quartiles.  Regarding the compensatory effect, it is easy to see that a country exhibiting a bad performance in one index, can compensate it with a good performance in another. However, this is not desirable since, for instance, bad health indices can be hidden by good GNI, which can exacerbes inequality in access to health systems.   
%
%Non-compensatory  methods have been proposed as an alternative to the HDI calculation method. For instance, \cite{Natoli2011} analyze three aggregation techniques designed for benchmarking and ranking of countries according to aggregated dimensions: additive methods, geometric aggregations, and non-compensatory methods.  They focus on the Condorcet approach as a non-compensatory aggregation technique for progress measures.  \cite{Lozano2009} propose to use the minimum of the component indexes in HDI instead of the arithmetic average. \cite{Mazziotta2015} compare two non-compensatory composite indices for measuring multidimensional phenomena and monitoring their changes over time: a non-linear composite index and a two-parameter function, which is an intermediate case between a compensatory and a full non-compensatory index. The authors found that the non-linear composite seems to be less compensatory that the second one.
%
%
%Non-compensatory  methods have been proposed to classify countries in the HDI Report.   \cite{Boujelben2016} propose an approach that integrates PROMETHEE and $K$-means. The underlying idea of their approach is based on the notion of belief distance between the alternatives and the centroids. \cite{Chen2018} propose a PROMETHEE-based algorithm, which integrates the $K$-means rationale, to cluster countries in the HDI Report. They found that the ordered clustering is highly consistent with the HDI ranks. \cite{DeSmet2012} propose an exact multi-criteria algorithm to find HDI ordered categories, based on valued preference degrees.  They show the consistency between the obtained ordered partition and the HDI ranking.  \cite{Monteiro2018} propose a supervised classification approach based on the ELECTRE TRI method in which the HDI categories are defined \emph{a priori} by using fixed category boundaries. Different from other proposals using the outranking-based models, these authors consider that $p=q=0$, that is, there is no imprecision. 
%
%Two types of imprecision have been highlighted by authors analyzing the quality of information used in the HDI calculation.  Firstly, the weighting process assigning equal importance levels to dimensions in HDI has been criticized and methods to deal with have been proposed \citep{Zheng2015}. In this article, we are not considering this kind of imprecision.  Secondly, the importance of considering imprecise data in constructing composite indicators has been remarked \citep{Cherchye2011}.  There are multiple indicators used for different kind of indexes, for instance, the Environmental Performance Index, the Internal Market Index, the Human Development Index, or the Technology Achievement Index. However, for some indicators only interval information is available, within what a true value is believed to lie.   \cite{Wolff2011} analyzed three sources of data error in HDI calculation and classification: measurement error due to data revisions, data error due to formula updating and misclassification due to inconsistent categories cut-off values. Actually,  measurement error from data updating impacts the rough data, the indices normalization and the HDI calculation. They found that from 11\% up to 34\% of all countries could be interpreted as misclassified in the development categories. These authors also found that on average the expected absolute deviation is nine rank positions. These results mean that interpretation of HDI ranks must be very careful.   
%
%
%
%Thus, several scholars have proposed  ordered clustering strategies to find a partition of countries, which we call the \emph{HDI problem}, based on non-compensatory multi-criteria approaches \citep{DeSmet2014,Boujelben2016}.  Most of non-compensatory approaches for computing the HDI clustering use the global outranking relation to model imprecise information regarding the evaluation of alternatives. Outranking was early proposed in Elimination Et Choix Traidusant la Realite (ELECTRE) methods \citep{figueira2010} and further became an essential feature in  Preference Ranking Organization METHod for Enrichment of Evaluations (PROMETHEE) methods \cite{brans85}. The outranking relation helps to model global  assertions from kind ``the alternative $b$ is at least as good as the alternative $a$'', based on information collected at the level of each criteria. 
%
%Some of the new MCDA clustering approaches to HDI integrate the $K$-means rationale \citep{DeSmet2009,Lolli2014,Panapakidis2018, Chen2018}, a popular greedy algorithm for partitioning a set of elements into a pre-defined number of clusters so as to minimize the distances to the cluster centroids (the cluster centers). Essentially, these clustering processes lie in two features of $K$-means. First, the definition of  an indifference-based metric measures how indifferent is an alternative to a centroid. Thus, an alternative is assigned to the cluster where the most indifferent centroid is found. Second, once all the alternatives have been assigned, the centroids are updated, using the information regarding the alternatives in their respective groups.  The process continues until a stop condition is satisfied. 
%
%Although the the $K$-means and outranking-based methods can be used to find the same number of country clusters proposed by the ranking-based HDI methodology, these use compensatory net flow aggregation processes to obtain global preference relations. Thus, the methods do not necessarily guarantee the separability between any pair of central actions representing two different categories, a desired property of preference-based classification processes \citep{roy2012}. This means that a strict preference relation between any pair of centroids at each criterion level is not necessarily satisfied. As a consequence, supplementary procedures must be defined to order the clusters.  In these methods,  an alternative must be compared to each other, at least once. This information is stored in the form of a $n \times n$ matrix which must be traversed through on each iteration of the clustering algorithm. These are $O(IKn^2) \sim O(n^2)$ processes, where $I, K$ are the number of iterations of the algorithm (before finding a solution) and the number of clusters, respectively. We argue that a $O(Kn)$ method may be implemented for the assignment process by simply comparing each country at most to the $K$ centroids in the model.  
%
%Methods based in the outranking relation need to model imprecise information by using two kind of parameters, defined for each criterion \citep{figueira2010}: the indifference and the preference thresholds. Most of time, these parameters are defined  with the decision-maker (DM) or expert judgement assistance. However, in the case of information regarding the HDI analysis, there is not an identified DM or even expert judgement can be variable because sources of information to evaluate countries in the three criteria is uncertain.  Thus, in this problem, considering single values does not seem appropriate.   
%
%
%In this article, we are going to model imprecision by the indifference and preference thresholds. However, differently from other outranking-based approaches, the parameter values are supposed to be realizations of  stochastic variables. Thus, the proposed approach is integrated  to a Monte Carlo Simulation process in which sets of  parameter values are passed as input to the ordered clustering algorithm.  In which follows, this procedure is explained in detail.



\section{Materials and methods}\label{notation}

\subsection{PROMETHEE II rationale}\label{promethee}

Multi-criteria clustering approaches have been developed that are applied to use the global outranking relation to model imprecise information regarding the evaluation of alternatives. Outranking was early proposed in Elimination Et Choix Traidusant la Realite (ELECTRE) methods \citep{figueira2010} and further became an essential feature in  Preference Ranking Organization METHod for Enrichment of Evaluations (PROMETHEE) methods \cite{brans85}. The outranking relation helps to model global  assertions from kind ``the alternative $b$ is at least as good as the alternative $a$'', based on information collected at the level of each criteria. Non-compensatory methods based on the outranking relation could lead to higher computational complexity. However, problems exist in which compensation among criteria is not allowable. 

Let $A=\{a_1,a_2,\ldots,a_n\}$ be a set of actions (e.g., countries);  let $F=\{g_1,g_2,\ldots,g_m\}$ be a coherent family of criteria used to evaluate each action and $W=\{w_j \mid 0 \leq w_j \leq 1, \sum_{j=1}^m w_j =1\}$ the criteria weights.  The vector of performances of an action  $(g_1(a),g_2(a),\ldots,g_m(a))$   is called the \emph{evaluation profile}. 
For any pair  $b,a \in A$, the  deviation of evaluations on criterion $j$, $=g_j(b)-g_j(a)$, can be calculated. PROMETHEE uses this deviation to compute a preference function $p_j(b,a)$, which allows to evaluate how preferred is an action over another, on the criterion $j$ \citep{brans85}.  Here, we use a modified version of the standard preference function

{\footnotesize
\begin{equation}
c_j(b,a) =
\begin{cases}
	0							& \mbox{if  $g_j(a)-g_j(b) > p_j$}, \\
	1							& \mbox{if  $g_j(a)-g_j(b) \leq q_j$},   \\
	\dfrac{g_j(b)-g_j(a)+p_j}{p_j-q_j} 	& \mbox{otherwise}, 				     	      
 \end{cases} 
 \label{credibility}
 \end{equation} 
}

\noindent
In \eqref{credibility}, $p_j, q_j$ are called the strict-preference and the indifference thresholds, respectively. Based on the $c_j(b,a) \,(j=1,\ldots,m)$ functions, the following indices can be computed,

\begin{equation}
\begin{cases}
C(b,a)= \sum_{j=1}^{m} w_jc_j(b,a) , \\
C(a,b)= \sum_{j=1}^{m} w_jc_j(b,a),
\end{cases}\label{indices}	
\end{equation}

\noindent
where $C(b,a)$ expresses with which degree  $b$ is preferred to $a$, over all the criteria.   Next, the level in which an element $b$ is preferred to, or it is outranked by,  the others elements in $A$ can be expressed in terms of two values: 

\begin{equation}
\begin{cases}
\psi^+(b)=\frac{1}{n-1} \sum_{a \in A, a \neq b} C(b,a) , \\
\psi^-(b)= \frac{1}{n-1}\sum_{a \in A, a \neq b} C(a,b),
\end{cases}\label{indices}
\end{equation}

\noindent
where $\psi^+(b)$ is called the \emph{positive outranking flow} of $b$ and $\psi^-(b)$ is called the \emph{negative outranking flow}.  In PROMETHEE II, a net outranking flow is calculated by the following expression

\begin{equation}
\psi(b)=\psi^+(b)-\psi^-(b). \label{phi}
\end{equation}

\noindent
This function satisfies $-1\leq \psi(b) \leq 1$. When $\psi(b)>0$, $b$ outranks all other alternatives in all criteria more than it is outranked. When $\psi(b)<0$,  $b$ is outranked by all other alternatives in all criteria more than it outranks them. This function can be used to build a complete pre-order (ranking) among actions. In \ref{concordance}, we show that $p_j(b,a)=1-c_j(a,b)$. Thus, it can be shown that the ranking induced by $\psi(b)$ is the same than the ranking induced by the standard PROMETHEE II.



\subsection{Cluster centroids and the indifference relation}\label{indifference}

Let $C_h, (h=1,\ldots,K; K\geq 2)$ be a set of ordered categories such that $C_1 \succ C_{2}\succ \ldots \succ C_K$, where  the relation $\succ$ means that for any $C_i, C_ j $ such that $i>j$, an element $a_i \in C_i$ is not worse than any element $a_j \in C_j$. Conversely, $a_j$ is worse than $a_i$, in terms of preferences.   A special set of actions $B=\{b_1,\ldots, b_K\}$ is defined, in which $b_h$ is a fictitious action called the \emph{centroid}, a central reference action being representative of $C_h$.

Now, let us define a trapezoidal fuzzy number (TrFN)  \citep{Ban2011}, as represented in Figure \ref{mu}.

\def \q {1}
\def \p {2}
\def \qq {1.5}
\def \pp {3}
\def \xmina{-3}
\def \xmaxa{.5}
\def \xminb{-.5}
\def \xmaxb{4}
\def \ymax{1}
\def \xb{2*\p}

\begin{figure}[hbtp]
\scriptsize
\centering
\begin{tikzpicture}
\begin{axis}[
		clip=false,
		xmin=0,xmax=5,
		ymin=0,ymax=1,
		height=4cm,
		width=7cm,
		axis line style={draw=none}, 
		xticklabels=\empty,	
		xtick=\empty,
		xtick={0},	
		ytick=\empty,
		xtick pos=left,
		xtick distance=1,
		every axis x label/.style={at={(current axis.right of origin)},anchor=west}
		]
		\addplot [domain=-\p:-\q,smooth, thick] {(x+\p)/(\p-\q)};
		\addplot [domain=\xmina:-\p,smooth, thick] {0};
		\addplot [domain=-\q:\qq,smooth, thick] {1};
		\addplot [smooth,dashed]  coordinates {(-\q,0)(-\q,\ymax)} node{} ;
		\addplot [smooth,->]  coordinates {(\xmina,0)(\xmina,\ymax+.5)} node[above]{$\mu_j(a,b_h)$} ;
		\addplot [domain=\pp:\xmaxb,smooth, thick] {0};
		\addplot [domain=-\p:\xmaxb,smooth,thin,->] {0};
		\addplot [domain=\qq:\pp,smooth, thick] {(-x+\pp)/(\pp-\qq)};
		\addplot [smooth,dashed]  coordinates {(\qq,0)(\qq,\ymax)} node{} ;
    		\node  at (axis cs:\qq-.1,-0.1) {\tiny$10+q_j$};
    		\node  at (axis cs:\pp,-0.1) {\tiny$10+p_j$};
    		\node  at (axis cs:-\p-.3,-0.1) {\tiny$10-p_j'$};
    		\node  at (axis cs:-\q-.1,-0.1) {\tiny$10-q_j'$};
    		\node  at (axis cs:0,-0.1) {\tiny$10$};
		\node  at (axis cs:4.5,0) {${\tiny g_j(a)}$};
\end{axis}
\end{tikzpicture}
\caption{Trapezoid function built from $c_j(b,a), c_j(a,b)$}
\label{mu}
\end{figure}


The TrFn $\mu_j(a,b_h)$ can be constructed from two outranking relations \citep{perny1992}. Actually,  let us define  

\begin{equation}
c^{inv}_j(a,b) =
\begin{cases}
	0							& \mbox{if  $g_j(b)-g_j(a) > p'_j$}, \\
	1							& \mbox{if  $g_j(b)-g_j(a) \leq q'_j$},   \\
	\dfrac{g_j(a)-g_j(b)+p'_j}{p'_j-q'_j} 	& \mbox{otherwise}. 				     	      
 \end{cases} 
 \label{invcredibility}
 \end{equation} 

\noindent
which we call the \emph{inverse preference function}, where inverse thresholds $p'_j,q'_j$ are introduced \citep{roy2012}, as shown in Figure \ref{mu}.  

Any alternative $a \in A$ can be evaluated as whether it belongs to a class $C_h$ or not, whenever a criterion $j$ is considered, by using the membership function $\mu_j(a,b_h)$.   Let us define 

\begin{equation}
i(a,b_h)=min\{C(b_h,a),C(a,b_h)\} \label{indifference}
\end{equation}
 
\noindent 
as an \emph{indifference function} evaluating in which degree $a$ belongs to $C_h$.  Note that $0\leq i(a,b_h)\leq 1$. If $i(a,b_h)=0$ means that $a$  should not be assigned  into the cluster $C_h$. On the contrary, $i(a,b_h)=1$ means that $a$ has to be assigned into that group. Thus, the function evaluates with which degree an action belongs to a cluster.


%\subsection{Clustering process}
%
% and the following assignment rules can be defined \citep{pereira2018}:
%
%\begin{enumerate}
%\item
%\emph{Descending Rule}. Let $\lambda \in [0.5,1]$ be a minimum credibility level. Decrease $h$ from $H+1$ until the first $t$ such that $\sigma_I(a,b_t)\geq \lambda$:
%
%\begin{enumerate}
%\item
%If $t=H+1$, assign $a$ to $C_H$.
%\item
%If $t=0$, assign $a$ to $C_1$.
%\item
%For $0<t<H+1$, 
%
%if $\min\{\sigma_I(a,b_t),\sigma_D(b_t,a)\} > \min\{\sigma_I(a,b_{t+1}),\sigma_D(b_{t+1},a)\}$ then assign $a$ to $C_t$; otherwise, assign $a$ to $C_{t+1}$.
%\end{enumerate} 
%
%\item
%\emph{Ascending Rule}. Let $\lambda \in [0.5,1]$ be a minimum credibility level. Increase $h$ from $0$ until the first $t$ such that $\sigma_D(b_t,a)\geq \lambda$:
%
%\begin{enumerate}
%\item
%If $t=1$, assign $a$ to $C_1$.
%\item
%If $t=H+1$, assign $a$ to $C_H$.
%\item
%For $0<t<H+1$, 
%
%if $\min\{\sigma_I(a,b_t),\sigma_D(b_t,a)\} > \min\{\sigma_I(a,b_{t-1}),\sigma_D(b_{t-1},a)\}$ then assign $a$ to $C_t$; otherwise, assign $a$ to $C_{t-1}$.
%\end{enumerate} 
%\end{enumerate}
%
%
%Essentially, the descending and the ascending rules evaluate how indifferent an alternative $a$ is to every $b_h$.  Thus, $a$ is assigned to the class for which it is closest.  In practice, these rules may assign an alternative to different classes. Therefore, in a particular application of the algorithm presented below, just one of them must be chosen.
%
%
%\subsection{$K$-means algorithm}
%
%$K$-means is a classical unsupervised method to partitioning a set of elements into a set of disjoint homogeneous groups, by minimizing the following objective function 
%
%\begin{equation}
%\min \sum_{h=1}^{K} \sum_{i=1}^{n} I_{ih} \left\| a_i-b_h \right\|,
%\end{equation}
%
%
%\noindent
%where  $I_{ih}=1$ if $a_i \in C_h$, $0$ otherwise; and $ \left\| a_i-b_h \right\|$ is the Euclidean distance between $a_i$ and $b_h$.  Classical $K$-means algorithm consists of three steps: (1) define $A, K, b_h$ as inputs; (2) assign elements of $A$ into clusters; (3) update the cluster centers and return to step (2), until a stop condition is satisfied.   
%
%Step (2) assigns an element $a_i$ to the group where the Euclidean distance between the element and the respective cluster center is minimized.  Step (3) updates the cluster centroids as follows
%
%
%\begin{equation}
%g_j(b_h) = \frac{1}{\mid C_h \mid} \sum_{a_i \in C_h} g_j(a_i) \quad j=1,\ldots,m. \label{newcentroid}
%\end{equation}
%
%\noindent
%Thus, the algorithm is iterated a number of times, or until the  change of centroids is less or equal than a given tolerance.


\subsection{P-WKM-E: a novel clustering process}\label{rule}

Let us assume that $A$ is ordered in terms of preferences, by using the PROMETHEE II method described in Section \ref{promethee}. Thus, a permutation $A^{(p)}=\{a_{i_1},a_{i_2},\ldots,a_{i_n} \}$ is obtained in which, for all $v \leq u$ it follows $a_{i_v} \preceq a_{i_u}$, i.e. $a_{i_u}$ is preferred or indifferent to $a_{i_v}$. Let $A^{(p)}$ be partitioned into groups $C_1 \succ C_{2}\succ \ldots \succ C_K$ with centroids $b_1, b_{2}, \ldots, b_K$, respectively. 

Essentially, MCDA clustering processes integrating $K$-means lie in two features \citep{DeSmet2009,Lolli2014,Panapakidis2018, Chen2018}. First, the definition of  an indifference-based metric that measures how indifferent is an alternative to a central alternative, or centroid, representing a category. Thus, an alternative is assigned to the cluster where the most indifferent centroid is found. Second, once all the alternatives have been assigned, the centroids are updated, using the information regarding the alternatives in their respective groups.  This process continues until a stop condition is satisfied.  

The Warped-$K$-means (WKM) is an approach based on $K$-means that uses the following procedure \citep{Leiva2013}: 1) building a permutation $A^{(p)}$ from the set $A$ of actions; 2) finding initial groups and centroids by defining boundaries of clusters; 3) moving boundaries and re-calculate the centroids, until the set of centroids is stable.
 In Figure \ref{boundaries} an example of permutation is represented, with three clusters,  boundaries  $L_h$ and centroids $b_h \, (h=0,1,2)$. The left boundary of a cluster is shown which coincides with the first element in each group. Actions in the set $[L_h, L_{h+1}[$  are assigned into $C_h$, and centroids could be calculated as usual in the $K$-means algorithm (i.e. computing the average profile). Note the  action $a$ in this figure.  If $i(a,b_0) < i(a,b_{1})$ then  $a$ should be better assigned into $C_1$.  Thus, re-assignment of this action means that $L_1$ should be moved to the left,   centroids should be updated and the process repeated. Several rounds could be applied, in ascending and descending directions, up to the centroids changes are minimal or a number of iterations is reached. \cite{Leiva2013} provides a detailed explanation of this method. 
 
 WKM was originally proposed for problems in which each action profile is modeled as a real vector, and distances between actions and centroids are computed by metric distances, e.g. the Euclidean one.  In this article, we propose to adapt it to cases in which similarity between an action and a centroid is replaced by the indifference relation presented in Section \ref{indifference}.  In addition, WKM bases the improvement of the $K$-means global similarity function as a corner step of its process. We propose do not use such a function and use instead two assignment rules.
  
\begin{figure}[hbtp]
\begin{center}
\fontsize{9}{9}{
\begin{tikzpicture}[
	scale=0.7,
		]
 
 \node at (0.1,1.3) {$L_0$};
 \draw[thin,dashed] (0.1,0.25) -- (0.1,1);
 \draw[thick,-*,red] (1,0) -- (0,0);
 \draw[thick,-*,red] (0,0) -- (1,0);
 \draw[thick,-*,red] (1,0) -- (1.8,0);

 \node at (2.15,0.4) {$b_0$};

 \draw[thick,-*,red] (1.8,0) -- (2.3,0);
 \draw[thick,-*,red] (2.3,0) -- (3.5,0);
 \draw[thick,-*,red] (3.5,0) -- (3.8,0);
 \draw[thick,-*,red] (3.8,0) -- (4.7,0);

 \node at (4.6,0.4) {$a$};

 \draw[thick,-*,green] (4.7,0) -- (5.5,0);

 \node at (5.3,1.3) {$L_1$};
 \draw[thin,dashed] (5.3,0.25) -- (5.3,1);

 \draw[thick,-*,green] (5.5,0) -- (6.5,0);
 \draw[thick,-*,green] (6.5,0) -- (7.5,0);

 \node at (7.35,0.4) {$b_1$};

 \draw[thick,-*,green] (7.5,0) -- (9,0);
 \draw[thick,-*,green] (9,0) -- (9.4,0);
 \draw[thick,-*,green] (9.4,0) -- (9.9,0);
 \draw[thick,-*,blue] (9.9,0) -- (10.7,0);

 \node at (10.5,1.3) {$L_2$};
 \draw[thin,dashed] (10.5,0.25) -- (10.5,1);

 \draw[thick,-*,blue] (10.7,0) -- (11,0);
 \draw[thick,-*,blue] (11,0) -- (11.2,0);
 \draw[thick,-*,blue] (11.2,0) -- (12.4,0);
 \draw[thick,-*,blue] (12.4,0) -- (13,0);

 \node at (12.9,0.4) {$b_2$};

 \draw[thick,-*,blue] (13,0) -- (13.4,0);
 \draw[thick,-*,blue] (13.4,0) -- (14.1,0);
 \draw[thick,-*,blue] (14.1,0) -- (15.5,0);

 
\end{tikzpicture}
}
\caption{Example of three clusters boundaries  $L_h$ and centroids $b_h \, (h=0,1,2)$}
\label{boundaries}   
\end{center}
\end{figure}


Therefore, let us define the following process:

\begin{enumerate}
\item
Building a a permutation $A^{(p)}$ from the set $A$, by using the PROMETHEE II method (Section \ref{promethee}).
\item
Compute initial $It=0$, $L_h, b_h \, (h=0,\ldots,K)$.
\item
Repeat 
\begin{enumerate}   
\item
\emph{Descending Rule}. Decrease $h$ from $K-1$ until $1$:

For $a\in \underleftarrow{C_h}$:

\begin{itemize}
\item
if $\min\{\sigma_I(a,b_h),\sigma_D(b_h,a)\} > \min\{\sigma_I(a,b_{h+1}),\sigma_D(b_{h+1},a)\}$ then:

\begin{itemize}
\item
Assign $a$ to $C_h$; otherwise, assign $a$ to $C_{h+1}$.

\item
Update $L_h, b_h \, (h=0,\ldots,K)$.
\end{itemize}
\end{itemize}


\item
\emph{Ascending Rule}. Increase $h$ from $1$ until the first $K$:

For $a\in \underrightarrow{C_h}$:

\begin{itemize}
\item
if $\min\{\sigma_I(a,b_h),\sigma_D(b_h,a)\} > \min\{\sigma_I(a,b_{h-1}),\sigma_D(b_{h-1},a)\}$ then:

\begin{itemize}
\item
Assign $a$ to $C_h$; otherwise, assign $a$ to $C_{h-1}$.

\item
Update $L_h, b_h \, (h=0,\ldots,K)$.
\end{itemize}
\end{itemize}

\item
$It=It+1$.

\end{enumerate}


Until $It = MaxIt$
\end{enumerate}


Expression $\underleftarrow{C_h}$ means that this set must be run from right to left. Similarly,  $\underrightarrow{C_h}$ means that it is run from left to right.  The descending and ascending rules are adapted from the ELECTRE TRI-C procedure introduced by \cite{almeida2008} in the context of multi-criteria sorting processes. The Repeat-Until loop mimics the iterative $K$-means algorithm. We propose to control it by a maximum number of iterations, $MaxIt$. 

Because this approach integrates features coming from PROMETHEE, Warped $K$-means and ELECTRE TRI-C,  we call this the \emph{P-WKM-E clustering method}.

Below, the procedure described is applied to the HDI problem.  Actions are identified and criteria defined.  Initially, we consider that thresholds are stochastic. Next, thresholds are fixed and weights are considered stochastic.   The whole process lead to a comparison between results produced by the approach proposed and the segmentation outcomes  published in the 2018 HDI Report.
 

%\subsection{Sorting process with SMAA-TRI}
%
%SMAA-TRI is a multi-criteria sorting method based on SMAA \citep{tervonen2007a}  which has been applied in  different problems \citep{karabay2016,tervonen2008a,scheffler2014,morais2014}. In SMAA-TRI, alternatives are sorted  into preference-ordered categories defined \emph{a priori} by two fictitious alternatives, called the upper and the lower bound. In order to assign alternatives to categories, each candidate $a$ is compared to each bound  $b$, based on the analysis of the global assertion ``$a$ is at least as good as $b$" (or ``$b$ is at least as good as $a$"), which is called the \emph{outranking preference relation}  \citep{figueira2010}. 
%
%Given a family of $K$ criteria $F=\{g_c \mid c=1,\ldots, K\}$, in order to apply SMAA-TRI, a set of parameters must be considered: the criteria weights $\mathbf{w}=(w_c)_{1\times K}$; the preference $\mathbf{p}=(p_c)_{1\times K}$, the indifference $\mathbf{q}=(q_c)_{1\times K}$ and the veto $\mathbf{v}=(v_c)_{1\times K}$ thresholds; and the cutting level ($\lambda$). In SMAA-TRI, an acceptability index $\pi_j^h$ describes the share of possible parameter values that have a DMU$j$ assigned to a category $C_h$.  This index is in the range $[0,1]$. A value $0$ indicates that there is no evidence that DMU$_j$ does belong to the category $C_h$, and $1$ means that the action surely belongs to that category.  If the parameters are stable, there is an $h$ such that $\pi_i^{h}=1$, in which case the assignment is said to be \emph{robust}.  This index is computed using Monte Carlo Simulation.

%\subsection{Clustering approach}\label{approach}
%
%The approach proposed here assumes that $K\geq 2$ ordered clusters must be found: $C_K \succ \ldots \succ C_1$. Similarly to the original $K$-means algorithm, an iterative  clustering process is performed until a stop condition is satisfied, as described  in Figure \ref{clustering}.  
%
%
%
%
%\begin{figure}[hbtp]
%\begin{center}
%\fontsize{7}{7}{
%\tikzstyle{bigbox}=[align=center,rectangle, draw=black, rounded corners,  anchor=north, minimum width=3.5cm, text width=3cm, minimum height=.7cm, node distance=.4cm]
%\tikzstyle{myarrow}=[->, >= triangle 45]
%\begin{tikzpicture}[
%	scale=0.6,
%	blueb/.style={
%  		draw=black,
%  		rounded corners,
%  		text width=2cm,
%  		font={\sffamily\color{black}}}
%		]
%    \node (defafw)[bigbox]
%        {
%            	1. Define $A, F, W, K, s=0$
%        };
%    \node (defpq)[bigbox,below= of defafw]
%        {
%            	2. Define $p_j,p'_j,q_j,q'_j,s=s+1$
%        };
%    \node (initcentroids)[bigbox,below= of defpq]
%        {
%            	3. Define $t=0, b_h^{(0)}$
%        };
%    \node (indices) [bigbox,   below=  of initcentroids]
%        {
%            	4. Compute $\sigma_D, \sigma_I$
%	};
%    \node (assign) [bigbox,   below=  of indices]
%        {
%            	5. Assign alternatives
%	};
%    \node (centroid) [bigbox,   below= of assign]
%        {
%            	6. Compute $t=t+1$ and  $b_h^{(t)}$ 
%	};
%   \node (decision) [draw, diamond, align=center, minimum width=2.5cm, minimum height=2.5cm, aspect=2, inner sep=-3pt, below=.4cm of centroid] 
%        {
%        $\mid b_h^{(t)} -b_h^{(t-1)} \mid < \epsilon$,\\
%        or\\
%	$t=Maxit$
%        };
%   
%   \node (stochastic) [draw, diamond, align=center,  minimum width=3.0cm, minimum height=2.5cm, aspect=2, inner sep=-3pt, below=.4cm of decision] 
%        {
%	$s=Maxst$
%        };
%
%    \node (final) [bigbox,   below=of stochastic]
%        {7. Compute frequency indices
%	};
%       
%   \draw[myarrow] (defafw.south) -> (defpq.north);
%   \draw[myarrow] (defpq.south) -> (initcentroids.north);
%   \draw[myarrow] (initcentroids.south) -> (indices.north);
%   \draw[myarrow] (indices.south) -> (assign.north);
%   \draw[myarrow] (assign.south) -> (centroid.north);
%  \draw[myarrow] (centroid.south) -> (decision.north);
%  \draw[myarrow] (decision.south) node[left] {yes} -> (stochastic.north);
%  \draw[myarrow] (decision.west) |- node[above] {no} ++(-17mm,0) --  ($(indices.west) + (-15mm,0)$) -> (indices.west);
%  \draw[myarrow] (stochastic.south) node[left] {yes} -> (final.north);
%  \draw[myarrow] (stochastic.west) |- node[above] {no} ++(-30mm,0) --  ($(defpq.west) + (-27mm,0)$) -> (defpq.west);
%
%\end{tikzpicture}
%}
%\caption{Outranking-based approach to ordered clustering}
%\label{clustering}   
%\end{center}
%\end{figure}
%
%Initially, the set of alternatives, the family of criteria, the criteria weights, and the number of clusters are identified.  Next, the imprecision parameters are set. Stochastic preference and indifference thresholds are considered in this approach. Thus, each time that the Step 2 is performed, a new set of values for $p_j,q_j,p'_j,q'_j \,(j=1,\ldots,m)$ are generated and used as input to the Step 3, where the new initial centroids are defined. 
%
%Step 4 consists of computing the expressions \eqref{indices}. In Step 5, the alternatives are assigned into the classes, using the following rule
%
%
%
%
%In Step 6, the evaluation profile of each new centroid in the iteration $t$ and class $C_h$ is computed as follows:
%
%\begin{equation}
%g_j(b_h^{(t)}) = \frac{1}{\mid C_h^{t,j} \mid} \sum_{a_i \in C_h^{t,j}} g_j(a_i) \quad j=1,\ldots,m,\label{newcentroid}
%\end{equation}
%
%\noindent
%where $C_h^{t,j}=\{a_i \in C_h \mid g_j(b_h^{(t)})-p'_j\leq g_j(a_i) \leq g_j(b_h^{(t)})+p_j\}$.  Whenever $C_h^{t,j}=\emptyset$, then $g_j(b_h^{(t)})=g_j(b_h^{(t-1)})$.   
%
%
%\cite{roy2012} propose that a \emph{separability condition} must be satisfied in classification problems in which a set of central reference alternatives is used: any two central reference alternatives must be separated enough such that the strong preference property holds, at the level of each criterion. We extend this property to the cases in which the direct and the inverse preference thresholds are used:
%
%\begin{cond}
%\emph{The set of reference alternatives $B$ fulfills the strict separability condition if and only if}
%
%\begin{equation}
%g_j(b_{h-1})+p_j \leq g_j(b_h)-p'_j \,,(h=2,\ldots,H; j=1,\ldots,n). \label{separability}
%\end{equation}
%
%\end{cond}
%
%\noindent
%If this condition is hold along the iterative process, the resulting cluster centers are ordered. The approach proposed satisfies this property.
%
%
%In this approach, thresholds are stochastic variables where values are generated by a Monte Carlo Simulation process. Thus, the whole process is repeated $Maxst$ times, once for each set of stochastic parameter values.  Given a set of parameter values, the inner loop in Figure \ref{clustering} iterates up to one out of two stop conditions applies: 1) the change of evaluation profiles is  lower than a pre-defined $\epsilon$ value, or 2) the maximum number of iterations, $Maxit$,  is reached.   
%
%In Step 7, the number of times that every alternative is assigned into each category is computed. Thus, a frequency profile is obtained for each alternative.   
%
%In the following section, this approach is applied to the HDI problem.





\section{Clustering HDI countries}\label{application}

Since 1990, the United Nations Development Programme (UNDP) releases the Human Development Index (HDI) to emphasize that people and their capabilities should be the ultimate criteria for assessing the development of a country, not only economic growth. Thus, the 2018 HDI ranking process evaluates  189 United Nations countries on the basis of three criteria aggregated from nine dimensions. In addition, based on the HDI quartiles, four ordered groups of countries are segmented: very high human development, high human development, medium human development, and low human development.  

In this article, data published in the 2018 HDI Report is retrieved to perform the analysis. Thus, there are 189 countries to be clustered. The family of criteria to be considered consists of the three indices: life expectancy ($g_1$), years of schooling ($g_2$) and Gross National Income, GNI  ($g_3$).  These indices are computed using the formulae defined in the HDI Technical Notes \citep{UNDP2019}.   

\subsection{Initial settings}

In order to have an idea about the number of clusters that should be considered in our approach, the $K$-means Elbow Method was roughly run on indices computed from HDI data. The Elbow Method is used to determine the optimal number of clusters in $K$-means clustering \citep{Ketchen1996}. This gives four clusters,    i.e. $K=4$, which parallels the number of groups defined in the Human Development Report. In order to define an initial set of centroids, the $K$-means algorithm is run.   The following initial centroids are found:

\begin{eqnarray}
b_1&=&(0.27, 0.25, 0.43), \nonumber\\
b_2&=&(0.51, 0.39, 0.64), \nonumber\\
b_3&=&(0.70, 0.53, 0.83), \nonumber\\
b_4&=&(0.90, 0.71, 0.93). \nonumber
\end{eqnarray}

\noindent
For each criterion $j$, the minimum distance between consecutive centroids $m_j=\min_{h} \{g_j(b_h)-g_j(b_{h-1})\}$ is calculated, then $m_1=0.19, m_2=0.14, m_3=0.10$. In order to guarantee a separability condition, the following restriction is defined

\begin{equation}
p'_j+p_j \leq m_j \, (j=1,2,3). \label{thresholds}
\end{equation}

%\noindent
%We suppose that $p_j,q_j,p'_j,q'_j$ do not depend on the position where an alternative is evaluated on the criterion $j$. There are situations in which that assumption may not be valid and more complete constraints should be considered. However, in this article we assume that the restriction \eqref{thresholds} is adequate.


\subsection{Stochastic thresholds}

Let us assume that  $p_j,q_j,p'_j,q'_j$ are uncertain.  We may assume that stochastic variables $\xi_{p_j},\xi_{q_j},\xi_{p'_j},\xi_{q'_j}$ correctly model each parameter. We assume that each stochastic variable is uniformly distributed in an interval  $[\xi_m, \xi_M]$. If a stochastic interval is defined for each variable, as $[m_j-0.1, m_j+0.1] \,(j=1,2,3)$, then the following linear equations system may be defined:

\begin{eqnarray}
p_1,p'_1 &\in& [0.090, 0.290], \nonumber\\
p_2,p'_2 &\in& [0.040, 0.240], \nonumber\\
p_3,p'_3 &\in& [0.000, 0.200], \nonumber\\
q_1,q'_1 &\in& [0.045, 0.145], \nonumber\\
q_2,q'_2 &\in& [0.020, 0.120], \nonumber\\
q_3,q'_3 &\in& [0.000, 0.100], \nonumber\\
p_1+p'_1 &\leq& 0.19, \nonumber\\
p_2+p'_2 &\leq& 0.14,  \nonumber\\
p_3+p'_3 &\leq& 0.10. \nonumber
\end{eqnarray}


\noindent
A set of 1000 random values is generated for each parameter which means that the clustering process is performed $1000$ times.  The number of iterations (see Section \ref{rule}) is defined as $MaxIt=30$ because preliminary simulations show that this is enough to reach stable centroids.  Weights are considered to be equal: $w_j=1/3$ for $j=1,2,3$. The  approach is implemented in Python and it is run in an Apple Mac 2.3 Intel i5 computer.

Results of clustering are shown in Table \ref{results}, where four groups of alternatives  are presented, as originally defined in the HDI ranking.  The codes of clusters are as follows: $C_4$, VERY HIGH DEVELOPMENT; $C_3$,  HIGH DEVELOPMENT;  $C_2$, MEDIUM DEVELOPMENT; $C_1$, LOW DEVELOPMENT.  Observe, for instance, that countries ranging from  1 (Norway) up to 62 (Seychelles) belong to the group of very high developed countries. Clusters built by the proposed approach are coded as $C_1, C_2, C_3, C_4$ and satisfy $C_1 \prec  C_2 \prec C_3 \prec C_4$.  




\newcommand\items{4}   %Number of classes
\arrayrulecolor{white} %Table line colors

\begin{table}[hbtp]
\caption{Ordered clustering  vs HDI development groups: stochastic thresholds and fixed weights}
\label{results}
\tiny
\hskip-4.0cm
\begin{tabular}{llll}
\begin{tabular}[t]{c*{\items}{|E}l}
\multicolumn{5}{c}{VERY HIGH DEVELOPMENT}\\\hline 
\multicolumn{1}{c}{Country} & 
\multicolumn{1}{c}{$C_4$} & 
\multicolumn{1}{c}{$C_3$} & 
\multicolumn{1}{c}{$C_2$} & 
\multicolumn{1}{c}{$C_1$} 
\\\hline
1	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
2	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
3	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
4	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
5	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
6	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
7	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
8	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
9	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
10	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
11	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
12	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
13	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
14	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
15	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
16	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
17	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
18	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
19	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
20	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
21	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
22	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
23	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
24	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
25	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
26	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
27	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
28	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
29	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
30	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
31	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
32	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
33	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
34	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
35	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
36	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
37	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
38	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
39	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
40	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
41	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
42	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
43	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
44	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
45	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
46	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
47	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
48	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
49	&	0.88 	&	0.12 	&	0.00 	&	0.00 	\\\hline
50	&	0.48 	&	0.52 	&	0.00 	&	0.00 	\\\hline
51	&	0.26 	&	0.74 	&	0.00 	&	0.00 	\\\hline
52	&	0.15 	&	0.85 	&	0.00 	&	0.00 	\\\hline
53	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
54	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
55	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
56	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
57	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
58	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
59	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
60	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
61	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
62	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
\end{tabular}

&

\begin{tabular}[t]{c*{\items}{|E}|}
\multicolumn{5}{c}{HIGH DEVELOPMENT}\\\hline 
\multicolumn{1}{c}{Country} & 
\multicolumn{1}{c}{$C_4$} & 
\multicolumn{1}{c}{$C_3$} & 
\multicolumn{1}{c}{$C_2$} & 
\multicolumn{1}{c}{$C_1$} 
\\\hline
63	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
64	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
65	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
66	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
67	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
68	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
69	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
70	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
71	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
72	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
73	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
74	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
75	&	0.00 	&	1.00 	&	0.00 	&	0.00 	\\\hline
76	&	0.00 	&	0.99 	&	0.01 	&	0.00 	\\\hline
77	&	0.00 	&	0.99 	&	0.01 	&	0.00 	\\\hline
78	&	0.00 	&	0.98 	&	0.02 	&	0.00 	\\\hline
79	&	0.00 	&	0.95 	&	0.05 	&	0.00 	\\\hline
80	&	0.00 	&	0.92 	&	0.08 	&	0.00 	\\\hline
81	&	0.00 	&	0.87 	&	0.13 	&	0.00 	\\\hline
82	&	0.00 	&	0.85 	&	0.15 	&	0.00 	\\\hline
83	&	0.00 	&	0.66 	&	0.34 	&	0.00 	\\\hline
84	&	0.00 	&	0.63 	&	0.37 	&	0.00 	\\\hline
85	&	0.00 	&	0.53 	&	0.47 	&	0.00 	\\\hline
86	&	0.00 	&	0.49 	&	0.51 	&	0.00 	\\\hline
87	&	0.00 	&	0.20 	&	0.80 	&	0.00 	\\\hline
88	&	0.00 	&	0.18 	&	0.82 	&	0.00 	\\\hline
89	&	0.00 	&	0.08 	&	0.92 	&	0.00 	\\\hline
90	&	0.00 	&	0.06 	&	0.94 	&	0.00 	\\\hline
91	&	0.00 	&	0.04 	&	0.96 	&	0.00 	\\\hline
92	&	0.00 	&	0.03 	&	0.97 	&	0.00 	\\\hline
93	&	0.00 	&	0.02 	&	0.98 	&	0.00 	\\\hline
94	&	0.00 	&	0.01 	&	0.99 	&	0.00 	\\\hline
95	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
96	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
97	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
98	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
99	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
100	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
101	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
102	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
103	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
104	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
105	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
106	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
107	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
108	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
109	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
110	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
111	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
112	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
113	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
114	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
115	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
116	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
\end{tabular}

&

\begin{tabular}[t]{c*{\items}{|E}|}
\multicolumn{5}{c}{MEDIUM DEVELOPMENT}\\\hline 
\multicolumn{1}{c}{Country} & 
\multicolumn{1}{c}{$C_4$} & 
\multicolumn{1}{c}{$C_3$} & 
\multicolumn{1}{c}{$C_2$} & 
\multicolumn{1}{c}{$C_1$} 
\\\hline
117	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
118	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
119	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
120	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
121	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
122	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
123	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
124	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
125	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
126	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
127	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
128	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
129	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
130	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
131	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
132	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
133	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
134	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
135	&	0.00 	&	0.00 	&	1.00 	&	0.00 	\\\hline
136	&	0.00 	&	0.00 	&	0.99 	&	0.01 	\\\hline
137	&	0.00 	&	0.00 	&	0.95 	&	0.05 	\\\hline
138	&	0.00 	&	0.00 	&	0.94 	&	0.06 	\\\hline
139	&	0.00 	&	0.00 	&	0.94 	&	0.06 	\\\hline
140	&	0.00 	&	0.00 	&	0.91 	&	0.09 	\\\hline
141	&	0.00 	&	0.00 	&	0.81 	&	0.18 	\\\hline
142	&	0.00 	&	0.00 	&	0.71 	&	0.28 	\\\hline
143	&	0.00 	&	0.00 	&	0.57 	&	0.43 	\\\hline
144	&	0.00 	&	0.00 	&	0.51 	&	0.49 	\\\hline
145	&	0.00 	&	0.00 	&	0.41 	&	0.59 	\\\hline
146	&	0.00 	&	0.00 	&	0.40 	&	0.60 	\\\hline
147	&	0.00 	&	0.00 	&	0.35 	&	0.65 	\\\hline
148	&	0.00 	&	0.00 	&	0.22 	&	0.78 	\\\hline
149	&	0.00 	&	0.00 	&	0.19 	&	0.81 	\\\hline
150	&	0.00 	&	0.00 	&	0.17 	&	0.83 	\\\hline
151	&	0.00 	&	0.00 	&	0.08 	&	0.91 	\\\hline
152	&	0.00 	&	0.00 	&	0.05 	&	0.95 	\\\hline
153	&	0.00 	&	0.00 	&	0.02 	&	0.98 	\\\hline
\end{tabular}

&

\begin{tabular}[t]{c*{\items}{|E}|}
\multicolumn{5}{c}{LOW DEVELOPMENT}\\\hline 
\multicolumn{1}{c}{Country} & 
\multicolumn{1}{c}{$C_4$} & 
\multicolumn{1}{c}{$C_3$} & 
\multicolumn{1}{c}{$C_2$} & 
\multicolumn{1}{c}{$C_1$} 
\\\hline
154	&	0.00 	&	0.00 	&	0.01 	&	0.99 	\\\hline
155	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
156	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
157	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
158	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
159	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
160	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
161	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
162	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
163	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
164	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
165	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
166	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
167	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
168	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
169	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
170	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
171	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
172	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
173	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
174	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
175	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
176	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
177	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
178	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
179	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
180	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
181	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
182	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
183	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
184	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
185	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
186	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
187	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
188	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
189	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
\end{tabular}

\end{tabular}

\end{table}


Given a row in a tabular structure, values indicate how frequently an alternative (country) is assigned into a cluster, regarding the $1000$ stochastic simulations.  For instance, the alternative 1 in the group VERY HIGH DEVELOPMENT, 100\% of times is assigned into $C_4$. Instead, country 49 is assigned into $C_4$  88\% of times and into $C_3$ 12\% of simulations. Colors help to recognize these frequencies: the more intense a color, the higher the frequency an alternative reaches in a cluster.  

The following results can be highlighted:

\begin{itemize}
\item
As observed in the VERY HIGH DEVELOPMENT group, the alternatives  1 up to 48   reach 100\% frequency in $C_4$.  The alternatives 49 up to 52 have some ambiguous arguments to be allocated into $C_4$ or $C_3$. However, countries 53-62 are 100\% of times assigned into $C_3$ (high development countries). 

\item
The group named HIGH DEVELOPMENT has three well defined zones: 1) from country 63 up to 75, assignment to $C_3$ is crisp; 2) Countries 76-94 present ambiguity in their assignments; 3)  From 95 up to 116, countries are allocated into $C_2$. 

\item
The group named MEDIUM DEVELOPMENT has two zones: 1) A crisp set of countries allocated to $C_2$, 100\% times; 2). An ambiguos set covering countries 136-153.

\item
The group named LOW DEVELOPMENT is almost free of ambiguity (exception for country 154).
\end{itemize}

Other approaches for clustering based on the outranking relation have not relieved in the uncertain nature of parameters, but only in the imprecise information available to evaluate countries, thus using deterministic thresholds \citep{DeSmet2012, DeSmet2014, Fernandez2010, Chen2018}. However, there is evidence showing that imprecision is uncertain, which depends on multiple factors, changing on time. \cite{Wolff2011} found that  the higher the development status of a country, the more precise are the reported data. This seems to encompass our results: countries in the upper part of very developed countries are strongly assigned to $C_4$.  These authors also found that when many countries are close to the group cut-off thresholds (quartiles), up to 45\% of the developing countries are misclassified.  Table \ref{results} shows this phenomenon. For instance, 40\% countries in the lower part of the VERY HIGH DEVELOPMENT group  are classified in $C_3$.  

\cite{Garcia2010} studied different sources of uncertainty both in data sources and methodological choices in the HDI calculation. They found that main sources of uncertainty resulted in non biased HDI rankings. A main finding was that shifts in ranking were minor in the upper part of the VERY HIGH DEVELOPMENT and the lower part of the LOW DEVELOPMENT  groups. However, the absolute shift in ranking seemed to be minor in all levels of development, which did not compromise the robustness of the HDI, regardless of the development level.  As a consequence, the HDI ranking remains robust.  Our results somehow contradicts such a statement. There are several countries in which the frequency of each of two consecutive classes are around 25\% and 55\% (e.g., countries 37, 40, 93, 101, 124, 137, 169).  This means that ranks of those countries will be different from the respective HDI ranks, because these can be assigned into categories different from the HDI development groups.




\subsection{Stochastic weights}


\cite{Garcia2010}  studied the distribution of the rankings derived from applying different weights, normalizations and an alternative functional form of life expectancy. They found that uncertainty in weights produced shift in rankings, but without significant bias regarding the HDI ranking.  In order to explore the impact of uncertain weights, we implement Monte Carlo simulations by considering $w_j \sim U(0,1) \, (j=1,2,3)$.  In Table \ref{results2} results obtained when uncertain weights and deterministic thresholds are considered:   $p_1=p'_1 =0.20;  p_2=p'_2 =0.14; p_3=p'_3 = 0.10; q_j=q'_j=p_j/2 \,(j=1,2,3)$.  


In this case, ambiguity of assignments increased. For instance,  in  the VERY HIGH DEVELOPMENT group there are now countries from 30 up to 62 that show less than perfect frequency in $C_4$.  The whole HIGH DEVELOPMENT group shows some level of ambiguity. In the MEDIUM DEVELOPMENT group, even if  countries 117-135 have down their level, they still have a high frequency to be assigned into $C_2$. The LOW DEVELOPMENT countries seem to be already having strong arguments to be placed into $C_1$.

This outcomes can be interpreted as a partially confirmatory evidence in favor of the \cite{Garcia2010}'s result regarding shift in rankings.  Although we may affirm that four groups of development exist, we did not found that the groups reported in the HDI Report and those built by our approach totally coincide. However, simulations reveal that uncertainty has an impact on outcomes. 

Let us define a minimal threshold of 80\% to accept that a country effectively belongs to a cluster.  In Table \ref{compared}, countries assignments obtained  with the original HDI Report and the two stochastic runs we have performed are shown. Ambiguos assignments are presented in columns $C_4-C_3$, $C_3-C_2$ and $C_2-C_1$.  This allows to identify the set of countries that could be more confidently  be allocated into specific groups.  For instance, it could be plausible that countries 1-47  belong to $C_4$ (VERY HIGH DEVELOPMENT).  

\arrayrulecolor{black} %Table line colors

\begin{table}[hbtp]
\caption{Assignments of HDI countries in three cases}
\label{compared}
\scriptsize
\begin{tabular}{llllllll}
\multicolumn{1}{c}{Method} 	& 
\multicolumn{1}{c}{$C_4$} 	& 
\multicolumn{1}{c}{$C_4-C_3$} & 
\multicolumn{1}{c}{$C_3$} 	& 
\multicolumn{1}{c}{$C_3-C_2$} & 
\multicolumn{1}{c}{$C_2$} 	& 
\multicolumn{1}{c}{$C_2-C_1$} & 
\multicolumn{1}{c}{$C_1$} 
\\\hline
HDI Report 			& 1-62	&		&63-116	&		&117-153	&			&154-189	\\
P-WKM-E (thresholds)	& 1-49	&50-51	&52-82	&83-86	&87-141	&142-148		&149-189	\\
P-WKM-E (weights)		& 1-47	&48-58	&59-79	&80-96	&97-142	&143-153		&154-189	\\\hline
\end{tabular}

\end{table}


The approach proposed has two components. Firstly, an ordered clustering is obtained because actions are first ordered and limits of clusters are re-located without alter the order.  Whenever the ascending or the descending rule are applied, clusters are initially ``frozen'' which means that actions inspected to re-assignment are taken as if these were not allocated yet.  This is the strategy that ELECTRE TRI-C sorting method applies \citep{almeida2008}.  Thus, moving boundaries occurs after any rule is used.   Secondly, in the special case of development indices, this approach seems to be well-adapted because, according to the reviewed literature, most of data available for evaluation is uncertain.  However,  we did not take into account, for instance, incomplete or vague information.  This kind of poor information needs to be considered in a future research.


\arrayrulecolor{white} %Table line colors

\begin{table}[hbtp]
\caption{Ordered clustering  vs HDI development groups: fixed thresholds and stochastic weights}
\label{results2}
\tiny
\hskip-4.0cm
\begin{tabular}{llll}
\begin{tabular}[t]{c*{\items}{|E}l}
\multicolumn{5}{c}{VERY HIGH DEVELOPMENT}\\\hline 
\multicolumn{1}{c}{Country} & 
\multicolumn{1}{c}{$C_4$} & 
\multicolumn{1}{c}{$C_3$} & 
\multicolumn{1}{c}{$C_2$} & 
\multicolumn{1}{c}{$C_1$} 
\\\hline
1	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
2	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
3	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
4	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
5	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
6	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
7	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
8	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
9	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
10	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
11	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
12	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
13	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
14	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
15	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
16	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
17	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
18	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
19	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
20	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
21	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
22	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
23	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
24	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
25	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
26	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
27	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
28	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
29	&	1.00 	&	0.00 	&	0.00 	&	0.00 	\\\hline
30	&	0.99 	&	0.01 	&	0.00 	&	0.00 	\\\hline
31	&	0.99 	&	0.01 	&	0.00 	&	0.00 	\\\hline
32	&	0.99 	&	0.01 	&	0.00 	&	0.00 	\\\hline
33	&	0.98 	&	0.02 	&	0.00 	&	0.00 	\\\hline
34	&	0.99 	&	0.01 	&	0.00 	&	0.00 	\\\hline
35	&	0.98 	&	0.02 	&	0.00 	&	0.00 	\\\hline
36	&	0.98 	&	0.02 	&	0.00 	&	0.00 	\\\hline
37	&	0.98 	&	0.02 	&	0.00 	&	0.00 	\\\hline
38	&	0.98 	&	0.02 	&	0.00 	&	0.00 	\\\hline
39	&	0.96 	&	0.04 	&	0.00 	&	0.00 	\\\hline
40	&	0.96 	&	0.04 	&	0.00 	&	0.00 	\\\hline
41	&	0.94 	&	0.06 	&	0.00 	&	0.00 	\\\hline
42	&	0.93 	&	0.07 	&	0.00 	&	0.00 	\\\hline
43	&	0.94 	&	0.06 	&	0.00 	&	0.00 	\\\hline
44	&	0.92 	&	0.08 	&	0.00 	&	0.00 	\\\hline
45	&	0.92 	&	0.08 	&	0.00 	&	0.00 	\\\hline
46	&	0.88 	&	0.12 	&	0.00 	&	0.00 	\\\hline
47	&	0.83 	&	0.17 	&	0.00 	&	0.00 	\\\hline
48	&	0.78 	&	0.22 	&	0.00 	&	0.00 	\\\hline
49	&	0.72 	&	0.28 	&	0.00 	&	0.00 	\\\hline
50	&	0.67 	&	0.33 	&	0.00 	&	0.00 	\\\hline
51	&	0.57 	&	0.43 	&	0.00 	&	0.00 	\\\hline
52	&	0.52 	&	0.47 	&	0.00 	&	0.00 	\\\hline
53	&	0.45 	&	0.55 	&	0.00 	&	0.00 	\\\hline
54	&	0.36 	&	0.64 	&	0.00 	&	0.00 	\\\hline
55	&	0.31 	&	0.68 	&	0.00 	&	0.00 	\\\hline
56	&	0.22 	&	0.77 	&	0.00 	&	0.00 	\\\hline
57	&	0.22 	&	0.78 	&	0.00 	&	0.00 	\\\hline
58	&	0.21 	&	0.79 	&	0.00 	&	0.00 	\\\hline
59	&	0.18 	&	0.82 	&	0.00 	&	0.00 	\\\hline
60	&	0.19 	&	0.81 	&	0.01 	&	0.00 	\\\hline
61	&	0.13 	&	0.87 	&	0.00 	&	0.00 	\\\hline
62	&	0.14 	&	0.85 	&	0.00 	&	0.00 	\\\hline
\end{tabular}

&

\begin{tabular}[t]{c*{\items}{|E}|}
\multicolumn{5}{c}{HIGH DEVELOPMENT}\\\hline 
\multicolumn{1}{c}{Country} & 
\multicolumn{1}{c}{$C_4$} & 
\multicolumn{1}{c}{$C_3$} & 
\multicolumn{1}{c}{$C_2$} & 
\multicolumn{1}{c}{$C_1$} 
\\\hline
63	&	0.11 	&	0.88 	&	0.01 	&	0.00 	\\\hline
64	&	0.10 	&	0.89 	&	0.02 	&	0.00 	\\\hline
65	&	0.09 	&	0.90 	&	0.01 	&	0.00 	\\\hline
66	&	0.06 	&	0.91 	&	0.02 	&	0.00 	\\\hline
67	&	0.06 	&	0.93 	&	0.01 	&	0.00 	\\\hline
68	&	0.04 	&	0.94 	&	0.02 	&	0.00 	\\\hline
69	&	0.04 	&	0.92 	&	0.04 	&	0.00 	\\\hline
70	&	0.02 	&	0.95 	&	0.04 	&	0.00 	\\\hline
71	&	0.02 	&	0.94 	&	0.05 	&	0.00 	\\\hline
72	&	0.01 	&	0.93 	&	0.06 	&	0.00 	\\\hline
73	&	0.01 	&	0.94 	&	0.06 	&	0.00 	\\\hline
74	&	0.01 	&	0.91 	&	0.08 	&	0.00 	\\\hline
75	&	0.01 	&	0.86 	&	0.13 	&	0.00 	\\\hline
76	&	0.01 	&	0.89 	&	0.10 	&	0.00 	\\\hline
77	&	0.01 	&	0.87 	&	0.13 	&	0.00 	\\\hline
78	&	0.01 	&	0.86 	&	0.14 	&	0.00 	\\\hline
79	&	0.00 	&	0.82 	&	0.17 	&	0.00 	\\\hline
80	&	0.00 	&	0.79 	&	0.21 	&	0.00 	\\\hline
81	&	0.00 	&	0.76 	&	0.24 	&	0.00 	\\\hline
82	&	0.00 	&	0.74 	&	0.26 	&	0.00 	\\\hline
83	&	0.00 	&	0.72 	&	0.28 	&	0.00 	\\\hline
84	&	0.00 	&	0.69 	&	0.31 	&	0.00 	\\\hline
85	&	0.00 	&	0.66 	&	0.34 	&	0.00 	\\\hline
86	&	0.00 	&	0.62 	&	0.38 	&	0.00 	\\\hline
87	&	0.00 	&	0.58 	&	0.42 	&	0.00 	\\\hline
88	&	0.00 	&	0.55 	&	0.45 	&	0.00 	\\\hline
89	&	0.00 	&	0.52 	&	0.48 	&	0.00 	\\\hline
90	&	0.00 	&	0.48 	&	0.52 	&	0.00 	\\\hline
91	&	0.00 	&	0.40 	&	0.60 	&	0.00 	\\\hline
92	&	0.00 	&	0.38 	&	0.62 	&	0.00 	\\\hline
93	&	0.00 	&	0.36 	&	0.64 	&	0.00 	\\\hline
94	&	0.00 	&	0.32 	&	0.68 	&	0.00 	\\\hline
95	&	0.00 	&	0.24 	&	0.76 	&	0.00 	\\\hline
96	&	0.00 	&	0.20 	&	0.79 	&	0.00 	\\\hline
97	&	0.00 	&	0.18 	&	0.82 	&	0.00 	\\\hline
98	&	0.00 	&	0.16 	&	0.84 	&	0.00 	\\\hline
99	&	0.00 	&	0.16 	&	0.84 	&	0.00 	\\\hline
100	&	0.00 	&	0.13 	&	0.87 	&	0.00 	\\\hline
101	&	0.00 	&	0.12 	&	0.88 	&	0.00 	\\\hline
102	&	0.00 	&	0.12 	&	0.88 	&	0.00 	\\\hline
103	&	0.00 	&	0.12 	&	0.88 	&	0.00 	\\\hline
104	&	0.00 	&	0.10 	&	0.90 	&	0.00 	\\\hline
105	&	0.00 	&	0.08 	&	0.92 	&	0.00 	\\\hline
106	&	0.00 	&	0.08 	&	0.92 	&	0.00 	\\\hline
107	&	0.00 	&	0.07 	&	0.93 	&	0.00 	\\\hline
108	&	0.00 	&	0.07 	&	0.92 	&	0.00 	\\\hline
109	&	0.00 	&	0.07 	&	0.93 	&	0.00 	\\\hline
110	&	0.00 	&	0.05 	&	0.95 	&	0.00 	\\\hline
111	&	0.00 	&	0.05 	&	0.94 	&	0.00 	\\\hline
112	&	0.00 	&	0.05 	&	0.94 	&	0.00 	\\\hline
113	&	0.00 	&	0.05 	&	0.95 	&	0.00 	\\\hline
114	&	0.00 	&	0.04 	&	0.95 	&	0.01 	\\\hline
115	&	0.00 	&	0.04 	&	0.96 	&	0.00 	\\\hline
116	&	0.00 	&	0.04 	&	0.96 	&	0.00 	\\\hline
\end{tabular}

&

\begin{tabular}[t]{c*{\items}{|E}|}
\multicolumn{5}{c}{MEDIUM DEVELOPMENT}\\\hline 
\multicolumn{1}{c}{Country} & 
\multicolumn{1}{c}{$C_4$} & 
\multicolumn{1}{c}{$C_3$} & 
\multicolumn{1}{c}{$C_2$} & 
\multicolumn{1}{c}{$C_1$} 
\\\hline
117	&	0.00 	&	0.03 	&	0.96 	&	0.01 	\\\hline
118	&	0.00 	&	0.03 	&	0.97 	&	0.01 	\\\hline
119	&	0.00 	&	0.02 	&	0.98 	&	0.00 	\\\hline
120	&	0.00 	&	0.03 	&	0.97 	&	0.00 	\\\hline
121	&	0.00 	&	0.03 	&	0.96 	&	0.01 	\\\hline
122	&	0.00 	&	0.02 	&	0.97 	&	0.01 	\\\hline
123	&	0.00 	&	0.02 	&	0.97 	&	0.01 	\\\hline
124	&	0.00 	&	0.02 	&	0.96 	&	0.02 	\\\hline
125	&	0.00 	&	0.01 	&	0.98 	&	0.02 	\\\hline
126	&	0.00 	&	0.01 	&	0.97 	&	0.02 	\\\hline
127	&	0.00 	&	0.01 	&	0.97 	&	0.02 	\\\hline
128	&	0.00 	&	0.01 	&	0.97 	&	0.02 	\\\hline
129	&	0.00 	&	0.01 	&	0.96 	&	0.03 	\\\hline
130	&	0.00 	&	0.01 	&	0.96 	&	0.04 	\\\hline
131	&	0.00 	&	0.01 	&	0.95 	&	0.04 	\\\hline
132	&	0.00 	&	0.01 	&	0.94 	&	0.05 	\\\hline
133	&	0.00 	&	0.01 	&	0.94 	&	0.05 	\\\hline
134	&	0.00 	&	0.01 	&	0.93 	&	0.06 	\\\hline
135	&	0.00 	&	0.01 	&	0.91 	&	0.08 	\\\hline
136	&	0.00 	&	0.00 	&	0.91 	&	0.08 	\\\hline
137	&	0.00 	&	0.00 	&	0.89 	&	0.11 	\\\hline
138	&	0.00 	&	0.00 	&	0.88 	&	0.12 	\\\hline
139	&	0.00 	&	0.00 	&	0.86 	&	0.14 	\\\hline
140	&	0.00 	&	0.00 	&	0.85 	&	0.15 	\\\hline
141	&	0.00 	&	0.00 	&	0.83 	&	0.17 	\\\hline
142	&	0.00 	&	0.00 	&	0.80 	&	0.20 	\\\hline
143	&	0.00 	&	0.00 	&	0.77 	&	0.22 	\\\hline
144	&	0.00 	&	0.00 	&	0.74 	&	0.25 	\\\hline
145	&	0.00 	&	0.00 	&	0.70 	&	0.30 	\\\hline
146	&	0.00 	&	0.00 	&	0.64 	&	0.36 	\\\hline
147	&	0.00 	&	0.00 	&	0.55 	&	0.45 	\\\hline
148	&	0.00 	&	0.00 	&	0.53 	&	0.47 	\\\hline
149	&	0.00 	&	0.00 	&	0.47 	&	0.53 	\\\hline
150	&	0.00 	&	0.00 	&	0.42 	&	0.58 	\\\hline
151	&	0.00 	&	0.00 	&	0.34 	&	0.66 	\\\hline
152	&	0.00 	&	0.00 	&	0.28 	&	0.72 	\\\hline
153	&	0.00 	&	0.00 	&	0.24 	&	0.75 	\\\hline
\end{tabular}

&

\begin{tabular}[t]{c*{\items}{|E}|}
\multicolumn{5}{c}{LOW DEVELOPMENT}\\\hline 
\multicolumn{1}{c}{Country} & 
\multicolumn{1}{c}{$C_4$} & 
\multicolumn{1}{c}{$C_3$} & 
\multicolumn{1}{c}{$C_2$} & 
\multicolumn{1}{c}{$C_1$} 
\\\hline
154	&	0.00 	&	0.00 	&	0.19 	&	0.81 	\\\hline
155	&	0.00 	&	0.00 	&	0.20 	&	0.80 	\\\hline
156	&	0.00 	&	0.00 	&	0.16 	&	0.84 	\\\hline
157	&	0.00 	&	0.00 	&	0.11 	&	0.89 	\\\hline
158	&	0.00 	&	0.00 	&	0.09 	&	0.91 	\\\hline
159	&	0.00 	&	0.00 	&	0.07 	&	0.93 	\\\hline
160	&	0.00 	&	0.00 	&	0.06 	&	0.94 	\\\hline
161	&	0.00 	&	0.00 	&	0.03 	&	0.96 	\\\hline
162	&	0.00 	&	0.00 	&	0.04 	&	0.96 	\\\hline
163	&	0.00 	&	0.00 	&	0.02 	&	0.98 	\\\hline
164	&	0.00 	&	0.00 	&	0.03 	&	0.97 	\\\hline
165	&	0.00 	&	0.00 	&	0.01 	&	0.98 	\\\hline
166	&	0.00 	&	0.00 	&	0.01 	&	0.99 	\\\hline
167	&	0.00 	&	0.00 	&	0.01 	&	0.99 	\\\hline
168	&	0.00 	&	0.00 	&	0.01 	&	0.99 	\\\hline
169	&	0.00 	&	0.00 	&	0.00 	&	0.99 	\\\hline
170	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
171	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
172	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
173	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
174	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
175	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
176	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
177	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
178	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
179	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
180	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
181	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
182	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
183	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
184	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
185	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
186	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
187	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
188	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
189	&	0.00 	&	0.00 	&	0.00 	&	1.00 	\\\hline
\end{tabular}

\end{tabular}

\end{table}

\section{Conclusions}\label{conclusions}
  
In this paper, a non-compensatory and stochastic multi-criteria clustering approach is proposed and it is applied to the group of countries included in the 2018 Human Development Index Report. Results obtained with this approach are compared to the deterministic 2018 HDI ranking. Findings show that an ordered set of clusters is built.  In addition, uncertainty shapes results, but it depends on the variable in which randomness is considered.  We have found that four groups of countries seem to be adequate, as proposed by the original HDI Report, but uncertainty makes ambiguity zones to appear which changes countries from clusters proposed by the HDI.

Therefore, we have found that considering uncertainty in clustering process can impact the classification of countries in the 2018 HDI Report. However, we may conclude that uncertainty in parameters used in outranking-based approaches and uncertainty in weights do not impact in the same way. Our approach is based on the outranking relation, which uses the following preferential parameters: the indifference and the preference thresholds, and the weights of criteria.  We have found that uncertainty in weights leads to more ambiguity in assignment of countries to clusters than uncertainty in thresholds.

A limitation of our approach is the usage of $K$-means like algorithm because results are dependent on the initial set of cluster centers.  To mitigate this drawback, we have used some heuristics to find the number and initial centroids. Anyway, future research is needed to  consider this feature in contexts of stochastic variables.
     
     
%\section*{Acknowledgement}

          
\section*{References}
\bibliographystyle{authoryear}
\bibliography{../bib/mybib-mcdm,../bib/mybib-mcdm-v1,../bib/mybib}





\appendix
\section{PROMETHEE II with a concordance preference function}\label{concordance}

In the original PROMETHEE method the preference function is defined as follows:

\begin{equation}
p_j(b,a) =
\begin{cases}
	0							& \mbox{if  $g_j(b)-g_j(a) > p_j$}, \\
	1							& \mbox{if  $g_j(b)-g_j(a) \leq q_j$},   \\
	\dfrac{g_j(b)-g_j(a)-q_j}{p_j-q_j} 	& \mbox{otherwise}, 				     	      
 \end{cases} 
 \label{p-credibility}
 \end{equation} 
 
In ELECTRE methods, \eqref{credibility} is called a partial concordance function \citep{figueira2010}, such that
 
\begin{equation}
c_j(a,b) =
\begin{cases}
	0							& \mbox{if  $g_j(b)-g_j(a) > p_j$}, \\
	1							& \mbox{if  $g_j(b)-g_j(a) \leq q_j$},   \\
	\dfrac{g_j(a)-g_j(b)+p_j}{p_j-q_j} 	& \mbox{otherwise}. 				     	      
 \end{cases} 
 \label{credibilityinv}
 \end{equation} 

\noindent
Thus, it is straight to show that $p_j(b,a)=1-c_j(a,b)$.  From this, it follows that 

\begin{eqnarray}
\Pi(a,b)	&=&\sum_{j}w_j(1-c_j(b,a)), \\
		&=&1- \sum_{j}w_jc_j(b,a), \\
		&=&1-C(b,a).
\end{eqnarray}

\noindent
In PROMETHEE, negative and positive flows are represented by functions $\phi^-,\phi^+$, such that 

\begin{equation}
\begin{cases}
\phi^+(b)=\frac{1}{n-1} \sum_{a \in A, a \neq b} \pi(b,a) , \\
\phi^-(b)= \frac{1}{n-1}\sum_{a \in A, a \neq b} \pi(a,b),
\end{cases}
\end{equation}

\noindent
which means that

\begin{eqnarray}
\phi^+(b)-\phi^-(b) 	&=& \frac{1}{n-1} \sum_{a \in A, a \neq b} \left((1-C(a,b))-(1-C(b,a))\right) , \\
				&=& \frac{1}{n-1} \sum_{a \in A, a \neq b} \left(C(b,a)-C(a,b)\right) \\
				&=& \psi^+(b)-\psi^-(b)
\end{eqnarray}

\noindent
where $\psi^+(b), \psi^-(b)$ may be interpreted as the positive and negative concordance flows.  This also means that the same preorder induced by the PROMETHEE II could be also obtained   by using the  function \eqref{credibility}, introduced in the Section \ref{promethee}.


\end{document}

